Format: Fall24-October10
Language: ru
Title: Автоматический анализ кода с помощью Bistr
Slug: bistr-code-analysis-tool
Categories: software

Если вам нужно провести анализ исходного кода проекта, но вы хотите автоматизировать этот процесс и использовать локальную мощность вашего компьютера, утилита Bistr может стать отличным решением. В этой статье мы разберем, как эта утилита помогает анализировать код с использованием модели машинного обучения Ollama.

<img src="https://demensdeum.com/blog/wp-content/uploads/2024/12/mediabistr-logo.jpeg">

<h2>Что такое Bistr?</h2>

Bistr — это утилита для анализа исходного кода, которая позволяет интегрировать локальную LLM (large language model) модель, такую как Ollama, для анализа и обработки кода. С помощью Bistr вы можете анализировать файлы на различных языках программирования, например, Python, C, Java, JavaScript, HTML и других.

Bistr использует модель для того, чтобы проверить файлы на соответствие определенным запросам, например, для поиска ответа на вопрос о функциональности кода или его части. Это позволяет получить структурированный анализ, который помогает в разработке, тестировании и поддержке проектов.

<h2>Как работает Bistr?</h2>

<ul>
<li>Загрузка состояния: Когда вы начинаете анализ, утилита проверяет, было ли ранее сохранено состояние анализа. Это помогает продолжить с того места, где вы остановились, без необходимости повторного анализа тех же файлов.</li>
<li>Анализ кода: Каждый файл анализируется с использованием модели Ollama. Утилита отправляет запрос к модели для анализа конкретного фрагмента кода. Модель возвращает информацию о релевантности кода в ответ на запрос, а также предоставляет текстовое объяснение, почему данный фрагмент имеет отношение к задаче.</li>
<li>Сохранение состояния: После анализа каждого файла состояние обновляется, чтобы в следующий раз продолжить с актуальной информацией.</li>
<li>Вывод результатов: Все результаты анализа можно экспортировать в HTML-файл, который содержит таблицу с рейтингом файлов по релевантности, что помогает понять, какие части кода наиболее важны для дальнейшего анализа.</li>
</ul>

<h2>Установка и запуск</h2>

Для использования Bistr необходимо установить и запустить Ollama — платформу, которая предоставляет LLM модели на вашей локальной машине. Инструкция по установке Ollama для macOS, Windows и Linux описана ниже.

Загрузите последнюю версию Bistr из git:
https://github.com/demensdeum/Bistr/

После установки Ollama и Bistr можно запускать анализ кода. Для этого нужно подготовить исходный код и указать путь к директории, содержащей файлы для анализа. Утилита позволяет продолжить анализ с того места, где вы остановились, а также предоставляет возможность экспортировать результаты в HTML-формате для удобства дальнейшего анализа.

Пример команды для запуска анализа:
<pre><code>
python bistr.py /path/to/code --model llama3.1:latest --output-html result.html --research "What is the purpose of this function?"
</code></pre>

В этой команде:

--model указывает модель, которая будет использоваться для анализа.
--output-html задает путь для сохранения результатов анализа в HTML-файле.
--research позволяет задать вопрос, на который вы хотите получить ответ, анализируя код.

<h2>Преимущества использования Bistr</h2>
<ul>
<li>Локальное выполнение: Анализ проводится на вашем компьютере без необходимости подключаться к облачным сервисам, что ускоряет процесс.</li>
<li>Гибкость: Вы можете анализировать код на различных языках программирования.</li>
<li>Автоматизация: Вся работа по анализу кода автоматизирована, что позволяет сэкономить время и силы, особенно при работе с большими проектами.</li>
</ul>